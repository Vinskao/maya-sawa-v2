# Maya Sawa V2 - Gen AI è‡ªå‹•å›è¦†å¹³å°

## ç³»çµ±æ¶æ§‹åœ–

```mermaid
graph TB
    subgraph "å‰ç«¯å±¤"
        A[ç”¨æˆ¶ä»‹é¢] --> B[API å®¢æˆ¶ç«¯]
    end

    subgraph "API å±¤"
        B --> A1[ask-with-model]
        B --> A2[chat-history]
        B --> A3[available-models]
        B --> A4[add-model]
        B --> A5[healthz]
        B --> A6[legacy-chat-history]
    end

    subgraph "Agent æœå‹™å±¤"
        AS[MayaAgentService<br/>LangGraph æ•´åˆ]
    end

    subgraph "LangGraph å·¥ä½œæµå±¤"
        WF[MayaAgentWorkflow<br/>åœ–å½¢åŒ–å·¥ä½œæµ]
        N1[æ„åœ–åˆ†é¡ç¯€é»<br/>FilterChain]
        N2[çŸ¥è­˜æª¢ç´¢ç¯€é»<br/>KMSourceManager]
        N3[å·¥å…·é¸æ“‡ç¯€é»<br/>æ™ºèƒ½å·¥å…·é¸æ“‡]
        N4[å·¥å…·åŸ·è¡Œç¯€é»<br/>PDF/OCR/è¨ˆç®—/æœç´¢]
        N5[AI å›æ‡‰ç”Ÿæˆç¯€é»<br/>LLM èª¿ç”¨]
        N6[çµæœä¿å­˜ç¯€é»<br/>è³‡æ–™æŒä¹…åŒ–]
        N7[éŒ¯èª¤è™•ç†ç¯€é»<br/>ç•°å¸¸è™•ç†]
    end

    subgraph "èƒ½åŠ›æ”¯æ’å±¤"
        LLM[LLM èƒ½åŠ›<br/>OpenAI/Gemini/Qwen]
        TOOLS[å·¥å…·èƒ½åŠ›<br/>PDF/OCR/è¨ˆç®—/æœç´¢]
        MEMORY[è¨˜æ†¶èƒ½åŠ›<br/>Redis/å‘é‡è¨˜æ†¶]
        RAG[RAG èƒ½åŠ›<br/>pgvector/æ··åˆæª¢ç´¢]
    end

    subgraph "è³‡æ–™å±¤"
        D1[(PostgreSQL<br/>Conversations/Articles)]
        D2[(Redis<br/>Cache/Memory)]
        D3[(RabbitMQ<br/>Celery Broker)]
    end

    subgraph "å¤–éƒ¨ç³»çµ±"
        E1[Paprika API]
        E2[OpenAI API]
        E3[Google Gemini API]
        E4[Qwen API]
    end

    %% API åˆ° Agent æœå‹™å±¤
    A1 --> AS

    %% Agent æœå‹™å±¤åˆ°å·¥ä½œæµå±¤
    AS --> WF

    %% å·¥ä½œæµç¯€é»é€£æ¥
    WF --> N1
    WF --> N2
    WF --> N3
    WF --> N4
    WF --> N5
    WF --> N6
    WF --> N7

    %% å·¥ä½œæµç¯€é»åˆ°èƒ½åŠ›å±¤
    N1 --> LLM
    N2 --> RAG
    N3 --> TOOLS
    N4 --> TOOLS
    N5 --> LLM
    N6 --> MEMORY

    %% èƒ½åŠ›å±¤åˆ°è³‡æ–™å±¤
    LLM --> D1
    TOOLS --> D1
    MEMORY --> D2
    RAG --> D1

    %% å¤–éƒ¨ç³»çµ±é€£æ¥
    LLM --> E2
    LLM --> E3
    LLM --> E4
    RAG --> E1

    %% æ¨£å¼å®šç¾©
    classDef api fill:#e8f5e8,stroke:#4caf50,stroke-width:2px
    classDef agent fill:#e3f2fd,stroke:#2196f3,stroke-width:2px
    classDef workflow fill:#fff3e0,stroke:#ff9800,stroke-width:2px
    classDef capability fill:#fce4ec,stroke:#e91e63,stroke-width:2px
    classDef data fill:#f1f8e9,stroke:#43a047,stroke-width:2px
    classDef external fill:#f3e5f5,stroke:#9c27b0,stroke-width:2px

    class A1,A2,A3,A4,A5,A6 api
    class AS agent
    class WF,N1,N2,N3,N4,N5,N6,N7 workflow
    class LLM,TOOLS,MEMORY,RAG capability
    class D1,D2,D3 data
    class E1,E2,E3,E4 external
```

## å°è©±æµç¨‹åœ– (LangGraph å·¥ä½œæµ)

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ¶
    participant F as å‰ç«¯
    participant A as API
    participant AS as Agent Service
    participant WF as LangGraph Workflow
    participant N1 as æ„åœ–åˆ†é¡ç¯€é»
    participant N2 as çŸ¥è­˜æª¢ç´¢ç¯€é»
    participant N3 as å·¥å…·é¸æ“‡ç¯€é»
    participant N4 as å·¥å…·åŸ·è¡Œç¯€é»
    participant N5 as AI å›æ‡‰ç”Ÿæˆç¯€é»
    participant N6 as çµæœä¿å­˜ç¯€é»
    participant DB as PostgreSQL
    participant R as Redis

    U->>F: ç™¼é€å•é¡Œ
    F->>A: POST /maya-v2/ask-with-model/
    A->>AS: è™•ç†è«‹æ±‚ (ä¿æŒ API æ ¼å¼å…¼å®¹)
    AS->>DB: å»ºç«‹ Conversation, Message
    
    Note over AS,WF: LangGraph å·¥ä½œæµåŸ·è¡Œ
    AS->>WF: åˆå§‹åŒ– AgentState
    WF->>N1: æ„åœ–åˆ†é¡ (FilterChain)
    N1-->>WF: è¿”å›æ„åœ–å’Œç½®ä¿¡åº¦
    
    WF->>N2: çŸ¥è­˜æª¢ç´¢ (KMSourceManager)
    N2->>DB: æ··åˆæª¢ç´¢ (trigram + pgvector)
    DB-->>N2: Top-K ç›¸é—œå…§å®¹
    N2-->>WF: è¿”å›çŸ¥è­˜ä¸Šä¸‹æ–‡
    
    WF->>N3: å·¥å…·é¸æ“‡ (æ™ºèƒ½åˆ†æ)
    N3-->>WF: è¿”å›éœ€è¦ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨
    
    alt éœ€è¦å·¥å…·
        WF->>N4: å·¥å…·åŸ·è¡Œ
        N4-->>WF: è¿”å›å·¥å…·åŸ·è¡Œçµæœ
    end
    
    WF->>N5: AI å›æ‡‰ç”Ÿæˆ (LLM èª¿ç”¨)
    N5-->>WF: è¿”å› AI å›æ‡‰
    
    WF->>N6: çµæœä¿å­˜
    N6->>DB: ä¿å­˜å°è©±è¨˜éŒ„
    N6->>R: æ›´æ–°èŠå¤©æ­·å²
    N6-->>WF: ä¿å­˜å®Œæˆ
    
    WF-->>AS: è¿”å› WorkflowResult
    AS->>DB: å»ºç«‹ AI Message
    AS-->>A: è¿”å› API å›æ‡‰ (ä¿æŒæ ¼å¼å…¼å®¹)
    A-->>F: å›å‚³ AI å›æ‡‰ + å·¥ä½œæµå…ƒæ•¸æ“š
    F-->>U: é¡¯ç¤ºå›æ‡‰

    Note over F,R: å¯ç”¨ GET /maya-sawa/qa/chat-history/{session_id}
```

## å‚³çµ±æµç¨‹åœ– (å°æ¯”)

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ¶
    participant F as å‰ç«¯
    participant A as API
    participant R as Redis
    participant DB as PostgreSQL
    participant KM as çŸ¥è­˜æª¢ç´¢
    participant AI as AI Provider

    U->>F: ç™¼é€å•é¡Œ
    F->>A: POST /maya-v2/ask-with-model/
    A->>DB: å»ºç«‹ Conversation, Message
    A->>R: è¿½åŠ ä½¿ç”¨è€…è¨Šæ¯(chat:session)
    A->>KM: Hybrid Search(trigram + pgvector)
    KM->>DB: æª¢ç´¢ articles.content/embedding
    DB-->>A: Top-K ç›¸é—œå…§å®¹
    
    alt æ‰¾åˆ°ç›¸é—œå…§å®¹
        A->>AI: èª¿ç”¨æŒ‡å®šæ¨¡å‹ + çŸ¥è­˜åº«å…§å®¹
        AI-->>A: å›å‚³ AI å›æ‡‰ + å¼•ç”¨è³‡è¨Š
    else æœªæ‰¾åˆ°ç›¸é—œå…§å®¹
        A->>AI: èª¿ç”¨æŒ‡å®šæ¨¡å‹
        AI-->>A: å›å‚³ AI å›æ‡‰ + ç„¡æ³•æ‰¾åˆ°çŸ¥è­˜åº«èªªæ˜
    end
    
    A->>R: è¿½åŠ  AI è¨Šæ¯(chat:session)
    A->>DB: å»ºç«‹ AI Message
    A-->>F: å›å‚³ AI å›æ‡‰ + çŸ¥è­˜åº«ç‹€æ…‹

    Note over F,R: å¯ç”¨ GET /maya-sawa/qa/chat-history/{session_id}
```

## å…¨æ–‡æª¢ç´¢æ··å’Œ Embedding æ¶æ§‹åœ–

```mermaid
graph TD
  %% ä½¿ç”¨è€…èˆ‡å…¥å£
  U["User"] --> Q["ask-with-model API<br/>question"]
  Q --> P["Full-text Retrieval Pipeline"]

  %% æª¢ç´¢æµç¨‹
  subgraph "Pipeline"
    P --> N["Normalize/Lowercase<br/>trim punctuation"]
    N --> E{"Compute Embedding?"}
    E -- Yes --> EM["OpenAI Embeddings<br/>(text-embedding-3-small) â†’ qvec(1536)"]
    E -- No --> SKIP["Skip vector branch"]

    %% Postgres æª¢ç´¢ï¼ˆTrigram èˆ‡ Vectorï¼‰
    subgraph "PostgreSQL"
      direction LR
      PG1["Trigram Search<br/>content % :query<br/>similarity(content, :query) as text_sim"]:::trgm
      PG2["Vector Search<br/>1 - (embedding <=> :qvec) as vec_sim"]:::vec
      IDX1["GIN Index<br/>idx_articles_content_trgm<br/>(content gin_trgm_ops)"]:::idx
      IDX2["IVFFlat Index<br/>idx_articles_embedding_ivfcos<br/>(embedding vector_cosine_ops)"]:::idx
      EXT1["EXTENSION pg_trgm<br/>set_limit(:min_sim)"]:::ext
      EXT2["EXTENSION pgvector"]:::ext
    end

    EM --> PG2
    SKIP -.-> PG1
    N --> PG1
    PG1 --> MRG["Merge & Rank<br/>score = 0.6*text_sim + 0.4*vec_sim"]
    PG2 --> MRG
    MRG --> TOPK["Top-K Articles"]
  end

  %% å¾Œè™•ç†èˆ‡å›å‚³
  TOPK --> CTX["Build Context from Articles<br/>(title + snippet)"]
  CTX --> AI["LLM Call (OpenAI/Gemini/Qwen/Mock)"]
  AI --> RESP["Answer + Citations/No Knowledge Notice"]
  RESP --> RDS["Redis ChatHistory<br/>chat:session:{sid}"]
  RESP --> OUT["API Response"]

  %% è³‡æ–™è¡¨èˆ‡ç´¢å¼•
  subgraph "articles schema"
    TBL["articles<br/>- id BIGSERIAL PK<br/>- file_path VARCHAR(500) UNIQUE<br/>- content TEXT NOT NULL<br/>- file_date TIMESTAMP NOT NULL<br/>- embedding vector(1536)"]:::tbl
  end
  TBL -. indexed by .-> IDX1
  TBL -. indexed by .-> IDX2

  %% æ¨£å¼
  classDef trgm fill:#e3f2fd,stroke:#1e88e5,stroke-width:1px
  classDef vec fill:#fce4ec,stroke:#d81b60,stroke-width:1px
  classDef idx fill:#fff3e0,stroke:#fb8c00,stroke-width:1px
  classDef ext fill:#ede7f6,stroke:#5e35b1,stroke-width:1px
  classDef tbl fill:#f1f8e9,stroke:#43a047,stroke-width:1px
```

## LangGraph å·¥ä½œæµæ¶æ§‹åœ–

```mermaid
graph TB
    subgraph "å·¥ä½œæµå…¥å£"
        START[ç”¨æˆ¶è«‹æ±‚] --> AS[MayaAgentService]
    end

    subgraph "LangGraph å·¥ä½œæµ"
        AS --> WF[MayaAgentWorkflow]
        
        subgraph "å·¥ä½œæµç¯€é»"
            WF --> N1[æ„åœ–åˆ†é¡ç¯€é»<br/>classify_intent_node]
            N1 --> N2[çŸ¥è­˜æª¢ç´¢ç¯€é»<br/>retrieve_knowledge_node]
            N2 --> N3[å·¥å…·é¸æ“‡ç¯€é»<br/>select_tools_node]
            N3 --> N4[å·¥å…·åŸ·è¡Œç¯€é»<br/>execute_tools_node]
            N4 --> N5[AI å›æ‡‰ç”Ÿæˆç¯€é»<br/>generate_response_node]
            N5 --> N6[çµæœä¿å­˜ç¯€é»<br/>save_result_node]
        end
        
        subgraph "éŒ¯èª¤è™•ç†"
            N1 --> ERROR[éŒ¯èª¤è™•ç†ç¯€é»<br/>error_handler_node]
            N2 --> ERROR
            N3 --> ERROR
            N4 --> ERROR
            N5 --> ERROR
            N6 --> ERROR
        end
    end

    subgraph "èƒ½åŠ›æ”¯æ’å±¤"
        N1 --> LLM[LLM èƒ½åŠ›<br/>OpenAI/Gemini/Qwen]
        N2 --> RAG[RAG èƒ½åŠ›<br/>pgvector/æ··åˆæª¢ç´¢]
        N3 --> TOOLS[å·¥å…·èƒ½åŠ›<br/>PDF/OCR/è¨ˆç®—/æœç´¢]
        N4 --> TOOLS
        N5 --> LLM
        N6 --> MEMORY[è¨˜æ†¶èƒ½åŠ›<br/>Redis/å‘é‡è¨˜æ†¶]
    end

    subgraph "è³‡æ–™å­˜å„²"
        LLM --> DB[(PostgreSQL)]
        RAG --> DB
        TOOLS --> DB
        MEMORY --> REDIS[(Redis)]
    end

    subgraph "å¤–éƒ¨ç³»çµ±"
        LLM --> OPENAI[OpenAI API]
        LLM --> GEMINI[Gemini API]
        LLM --> QWEN[Qwen API]
        RAG --> PAPRIKA[Paprika API]
    end

    %% æ¨£å¼å®šç¾©
    classDef entry fill:#e8f5e8,stroke:#4caf50,stroke-width:2px
    classDef workflow fill:#e3f2fd,stroke:#2196f3,stroke-width:2px
    classDef node fill:#fff3e0,stroke:#ff9800,stroke-width:2px
    classDef capability fill:#fce4ec,stroke:#e91e63,stroke-width:2px
    classDef storage fill:#f1f8e9,stroke:#43a047,stroke-width:2px
    classDef external fill:#f3e5f5,stroke:#9c27b0,stroke-width:2px

    class START,AS entry
    class WF workflow
    class N1,N2,N3,N4,N5,N6,ERROR node
    class LLM,RAG,TOOLS,MEMORY capability
    class DB,REDIS storage
    class OPENAI,GEMINI,QWEN,PAPRIKA external
```

## å¿«é€Ÿé–‹å§‹
- Python 3.12+
- PostgreSQL 13+ (æ”¯æ´ pgvector)
- Redis 6.0+
- Poetry

### æœ¬åœ°é–‹ç™¼è¨­ç½®

```bash
# 1. å…‹éš†å°ˆæ¡ˆ
git clone <repository-url>
cd maya-sawa-v2

# 2. å®‰è£ Poetry (å¦‚æœå°šæœªå®‰è£)
curl -sSL https://install.python-poetry.org | python3 -

# 3. å®‰è£ä¾è³´
poetry install

# 4. è¤‡è£½ç’°å¢ƒè®Šé‡æ¨¡æ¿
cp .env.example .env

# 5. ç·¨è¼¯ .env æ–‡ä»¶ï¼Œå¡«å…¥ä½ çš„é…ç½®
# å¿…è¦é…ç½®ï¼š
# - DATABASE_URL æˆ– DB_* è®Šæ•¸
# - REDIS_URL
# - OPENAI_API_KEY (å¦‚æœä½¿ç”¨ OpenAI)
# - GOOGLE_API_KEY (å¦‚æœä½¿ç”¨ Gemini)
# - QWEN_API_KEY (å¦‚æœä½¿ç”¨ Qwen)

# 6. æ•¸æ“šåº«é·ç§»
poetry run python manage.py migrate

# 7. è¨­ç½® AI æ¨¡å‹
poetry run python manage.py setup_ai_models

# 8. å‰µå»ºè¶…ç´šç”¨æˆ¶
poetry run python manage.py createsuperuser

# 9. å•Ÿå‹•æœå‹™ï¼ˆåŒæ™‚å•Ÿå‹• Django å’Œ Celery Workerï¼‰
lsof -ti:8000 | xargs kill -9 2>/dev/null; poetry run python manage.py runserver & poetry run celery -A config worker -l info -Q maya_v2

```

### ç’°å¢ƒè®Šæ•¸é…ç½®

#### è³‡æ–™åº«é…ç½®
```bash
# æ–¹å¼ 1: ä½¿ç”¨ DATABASE_URL
DATABASE_URL=postgres://user:password@localhost:5432/maya_sawa_v2

# æ–¹å¼ 2: ä½¿ç”¨åˆ†é›¢è®Šæ•¸
DB_CONNECTION=pgsql
DB_HOST=localhost
DB_PORT=5432
DB_DATABASE=maya_sawa_v2
DB_USERNAME=user
DB_PASSWORD=password
DB_SSLMODE=require

# è³‡æ–™åº«é€£æ¥æ± è¨­ç½®ï¼ˆé™åˆ¶æœ€å¤š 5 å€‹é€£æ¥ï¼‰
CONN_MAX_AGE=60
DB_MAX_CONNS=5
```

#### AI æä¾›è€…é…ç½®
ç›®å‰æœ¬å°ˆæ¡ˆä¸»è¦ä½¿ç”¨ OpenAIï¼Œå…¶ä»–æä¾›è€…ï¼ˆGeminiã€Qwenï¼‰å·²é…ç½®ä½†éœ€è¦é¡å¤–è¨­ç½®ï¼š
```bash
# å•Ÿç”¨çš„æä¾›è€…
ENABLED_PROVIDERS=openai,gemini,qwen,mock

# OpenAI é…ç½®
OPENAI_API_KEY=your_openai_api_key
OPENAI_ORGANIZATION=your_org_id
OPENAI_MODELS=gpt-4o-mini,gpt-4o,gpt-4.1-nano,gpt-3.5-turbo
OPENAI_AVAILABLE_MODELS=gpt-4o-mini,gpt-4o
OPENAI_DEFAULT_MODEL=gpt-4o-mini

# Google Gemini é…ç½®
GOOGLE_API_KEY=your_google_api_key
GEMINI_MODELS=gemini-1.5-flash,gemini-1.5-pro
GEMINI_AVAILABLE_MODELS=gemini-1.5-flash
GEMINI_DEFAULT_MODEL=gemini-1.5-flash

# Qwen é…ç½®
QWEN_API_KEY=your_qwen_api_key
QWEN_MODELS=qwen-turbo,qwen-plus
QWEN_AVAILABLE_MODELS=qwen-turbo
QWEN_DEFAULT_MODEL=qwen-turbo
```

**æ³¨æ„ï¼š**
- ç›®å‰ç³»çµ±é è¨­åªå•Ÿç”¨ OpenAI æä¾›è€…
- å¦‚éœ€ä½¿ç”¨ Geminiï¼Œè«‹è¨­ç½® `GOOGLE_API_KEY` ä¸¦åœ¨ `ENABLED_PROVIDERS` ä¸­åŠ å…¥ `gemini`
- å¦‚éœ€ä½¿ç”¨ Qwenï¼Œè«‹è¨­ç½® `QWEN_API_KEY` ä¸¦åœ¨ `ENABLED_PROVIDERS` ä¸­åŠ å…¥ `qwen`
- æ‰€æœ‰æä¾›è€…éƒ½æ”¯æ´ Mock æ¨¡å¼ç”¨æ–¼æ¸¬è©¦

#### CORS é…ç½®
```bash
# å…è¨±çš„ä¾†æº
CORS_ALLOWED_ORIGINS=http://localhost:4321,http://127.0.0.1:4321

# API å®‰å…¨é…ç½®
API_REQUIRE_AUTHENTICATION=false
API_REQUIRE_CSRF=false
API_RATE_LIMIT_ENABLED=false
```

## API ä½¿ç”¨èˆ‡æ¸¬è©¦

### ğŸ“‹ å®Œæ•´ API æŸ¥è©¢éç¨‹è¨˜éŒ„

#### **æ–¹å¼ä¸€ï¼šåŒæ­¥è™•ç†ï¼ˆæ¨è–¦ç”¨æ–¼ç°¡å–®å•é¡Œï¼‰**

##### 1. å¥åº·æª¢æŸ¥
```bash
curl -X GET "http://127.0.0.1:8000/healthz"
```
**é æœŸå›æ‡‰ï¼š**
```json
{
  "status": "healthy",
  "timestamp": "2025-08-25T10:30:00Z"
}
```

##### 2. ç²å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
```bash
curl -X GET "http://127.0.0.1:8000/maya-v2/available-models/"
```
**é æœŸå›æ‡‰ï¼š**
```json
[
  {
    "id": 6,
    "name": "GPT-4o Mini",
    "provider": "openai",
    "is_active": true
  },
  {
    "id": 7,
    "name": "GPT-4o",
    "provider": "openai",
    "is_active": true
  }
]
```

##### 3. æäº¤åŒæ­¥å•é¡Œ
```bash
curl -X POST "http://127.0.0.1:8000/maya-v2/ask-with-model/" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "ä½ å¥½ï¼Œé€™æ˜¯ä¸€å€‹æ¸¬è©¦å•é¡Œã€‚è«‹ç°¡å–®ä»‹ç´¹ä¸€ä¸‹ä½ è‡ªå·±ã€‚",
    "model_name": "gpt-4o-mini",
    "sync": true,
    "use_knowledge_base": true
  }'
```
**é æœŸå›æ‡‰ï¼š**
```json
{
  "session_id": "qa-1f44cbba",
  "conversation_id": "de71a9c9-c932-4735-bf0e-4bf3a8c477dc",
  "question": "ä½ å¥½ï¼Œé€™æ˜¯ä¸€å€‹æ¸¬è©¦å•é¡Œã€‚è«‹ç°¡å–®ä»‹ç´¹ä¸€ä¸‹ä½ è‡ªå·±ã€‚",
  "ai_model": {
    "id": 6,
    "name": "GPT-4o Mini",
    "provider": "openai"
  },
  "status": "completed",
  "ai_response": "ä½ å¥½ï¼æˆ‘æ˜¯ä¸€å€‹ AI åŠ©æ‰‹...",
  "knowledge_used": true,
  "knowledge_citations": [
    {
      "article_id": 16,
      "title": "ç›¸é—œæ–‡ç« æ¨™é¡Œ",
      "file_path": "article.md",
      "source": "paprika_16",
      "source_url": "https://example.com/article.md",
      "provider": "Paprika"
    }
  ],
  "message": "AIå›ç­”å·²å®Œæˆ"
}
```

---

#### **æ–¹å¼äºŒï¼šç•°æ­¥è™•ç†ï¼ˆæ¨è–¦ç”¨æ–¼è¤‡é›œå•é¡Œï¼‰**

##### 1. æäº¤ç•°æ­¥å•é¡Œ
```bash
curl -X POST "http://127.0.0.1:8000/maya-v2/ask-with-model/" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Java ä¸­çš„å¤šç·šç¨‹æ˜¯ä»€éº¼ï¼Ÿè«‹è©³ç´°è§£é‡‹ä¸¦æä¾›ä»£ç¢¼ç¯„ä¾‹ã€‚",
    "model_name": "gpt-4o-mini",
    "sync": false,
    "use_knowledge_base": true
  }'
```
**ç«‹å³å›æ‡‰ï¼š**
```json
{
  "task_id": "a7e35f8e-c09d-4a25-868b-dd97173c00c6",
  "status": "queued",
  "message": "Task has been queued for processing",
  "conversation_id": "461daa00-29ad-45c0-bb95-5170a6bbbe3c",
  "question": "Java ä¸­çš„å¤šç·šç¨‹æ˜¯ä»€éº¼ï¼Ÿè«‹è©³ç´°è§£é‡‹ä¸¦æä¾›ä»£ç¢¼ç¯„ä¾‹ã€‚",
  "ai_model": {
    "id": 6,
    "name": "GPT-4o Mini",
    "provider": "openai"
  }
}
```

##### 2. æŸ¥è©¢ä»»å‹™ç‹€æ…‹ï¼ˆè¼ªè©¢ï¼‰
```bash
curl -X GET "http://127.0.0.1:8000/maya-v2/task-status/a7e35f8e-c09d-4a25-868b-dd97173c00c6"
```

**ä»»å‹™åŸ·è¡Œä¸­ï¼š**
```json
{
  "task_id": "a7e35f8e-c09d-4a25-868b-dd97173c00c6",
  "status": "STARTED",
  "message": "Task is currently being processed"
}
```

**ä»»å‹™å®Œæˆï¼š**
```json
{
  "task_id": "a7e35f8e-c09d-4a25-868b-dd97173c00c6",
  "status": "SUCCESS",
  "ai_response": "Java ä¸­çš„å¤šç·šç¨‹æ˜¯æŒ‡...",
  "conversation_id": "461daa00-29ad-45c0-bb95-5170a6bbbe3c",
  "question": "Java ä¸­çš„å¤šç·šç¨‹æ˜¯ä»€éº¼ï¼Ÿè«‹è©³ç´°è§£é‡‹ä¸¦æä¾›ä»£ç¢¼ç¯„ä¾‹ã€‚",
  "ai_model": {
    "id": 6,
    "name": "GPT-4o Mini",
    "provider": "openai"
  },
  "processing_time": 2.5,
  "completed_at": "2025-08-25T10:52:40Z",
  "knowledge_used": true,
  "knowledge_citations": [
    {
      "article_id": 16,
      "title": "Java å¤šç·šç¨‹æŒ‡å—",
      "file_path": "java-multithreading.md",
      "source": "paprika_16",
      "source_url": "https://example.com/java-multithreading.md",
      "provider": "Paprika"
    }
  ],
  "metadata": {
    "task_id": "a7e35f8e-c09d-4a25-868b-dd97173c00c6",
    "status": "completed"
  }
}
```

**ä»»å‹™å¤±æ•—ï¼š**
```json
{
  "task_id": "a7e35f8e-c09d-4a25-868b-dd97173c00c6",
  "status": "FAILURE",
  "error": "è™•ç†å¤±æ•—çš„è©³ç´°éŒ¯èª¤è¨Šæ¯",
  "traceback": "éŒ¯èª¤å †ç–Šè¿½è¹¤"
}
```

---

#### **æ–¹å¼ä¸‰ï¼šç‰¹å®šåŠŸèƒ½æ¸¬è©¦**

##### 1. æ¸¬è©¦å·¥å…·é¸æ“‡åŠŸèƒ½ï¼ˆè¨ˆç®—å™¨ï¼‰
```bash
curl -X POST "http://127.0.0.1:8000/maya-v2/ask-with-model/" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "è«‹å¹«æˆ‘è¨ˆç®— 123 + 456 ç­‰æ–¼å¤šå°‘ï¼Ÿ",
    "model_name": "gpt-4o-mini",
    "sync": true,
    "use_knowledge_base": true
  }'
```

##### 2. æ¸¬è©¦ç·¨ç¨‹å•é¡Œï¼ˆçŸ¥è­˜åº«æª¢ç´¢ï¼‰
```bash
curl -X POST "http://127.0.0.1:8000/maya-v2/ask-with-model/" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Python ä¸­çš„è£é£¾å™¨æ˜¯ä»€éº¼ï¼Ÿ",
    "model_name": "gpt-4o-mini",
    "sync": true,
    "use_knowledge_base": true
  }'
```

##### 3. æ¸¬è©¦èŠå¤©æ­·å²æŸ¥è©¢
```bash
curl -X GET "http://127.0.0.1:8000/maya-sawa/qa/chat-history/test_session_123/"
```
**é æœŸå›æ‡‰ï¼š**
```json
{
  "session_id": "test_session_123",
  "meta": {
    "created_at": "2025-08-25T10:30:00Z",
    "message_count": 4
  },
  "messages": [
    {
      "role": "user",
      "content": "ä½ å¥½",
      "timestamp": "2025-08-25T10:30:00Z"
    },
    {
      "role": "assistant",
      "content": "ä½ å¥½ï¼æˆ‘æ˜¯ AI åŠ©æ‰‹...",
      "timestamp": "2025-08-25T10:30:05Z"
    }
  ]
}
```

---

### ğŸ”„ å‰ç«¯å¯¦ç¾ç¯„ä¾‹

#### **JavaScript ç•°æ­¥è™•ç†å®Œæ•´æµç¨‹**

```javascript
class MayaSawaAPI {
  constructor(baseURL = 'http://127.0.0.1:8000') {
    this.baseURL = baseURL;
  }

  // æäº¤å•é¡Œï¼ˆç•°æ­¥ï¼‰
  async submitQuestion(question, modelName = 'gpt-4o-mini', useKnowledgeBase = true) {
    const response = await fetch(`${this.baseURL}/maya-v2/ask-with-model/`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        question,
        model_name: modelName,
        sync: false,
        use_knowledge_base: useKnowledgeBase
      })
    });
    
    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }
    
    return await response.json();
  }

  // æŸ¥è©¢ä»»å‹™ç‹€æ…‹
  async getTaskStatus(taskId) {
    const response = await fetch(`${this.baseURL}/maya-v2/task-status/${taskId}`);
    
    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }
    
    return await response.json();
  }

  // è¼ªè©¢ä»»å‹™çµæœ
  async pollTaskResult(taskId, interval = 2000, maxAttempts = 30) {
    let attempts = 0;
    
    return new Promise((resolve, reject) => {
      const poll = async () => {
        try {
          const status = await this.getTaskStatus(taskId);
          
          if (status.status === 'SUCCESS') {
            resolve(status);
          } else if (status.status === 'FAILURE') {
            reject(new Error(status.error || 'Task failed'));
          } else if (attempts >= maxAttempts) {
            reject(new Error('Polling timeout'));
          } else {
            attempts++;
            setTimeout(poll, interval);
          }
        } catch (error) {
          reject(error);
        }
      };
      
      poll();
    });
  }

  // ç²å–å¯ç”¨æ¨¡å‹
  async getAvailableModels() {
    const response = await fetch(`${this.baseURL}/maya-v2/available-models/`);
    
    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }
    
    return await response.json();
  }
}

// ä½¿ç”¨ç¯„ä¾‹
const api = new MayaSawaAPI();

// æäº¤å•é¡Œä¸¦è¼ªè©¢çµæœ
async function askQuestion(question) {
  try {
    console.log('æäº¤å•é¡Œ:', question);
    
    // 1. æäº¤å•é¡Œ
    const submitResult = await api.submitQuestion(question);
    console.log('ä»»å‹™å·²æäº¤:', submitResult.task_id);
    
    // 2. è¼ªè©¢çµæœ
    const result = await api.pollTaskResult(submitResult.task_id);
    console.log('AI å›ç­”:', result.ai_response);
    
    return result;
  } catch (error) {
    console.error('éŒ¯èª¤:', error.message);
  }
}

// ä½¿ç”¨
askQuestion("Java ä¸­çš„å¤šç·šç¨‹æ˜¯ä»€éº¼ï¼Ÿ");
```

---

### ğŸ“Š API ç‹€æ…‹ç¢¼èªªæ˜

| ç‹€æ…‹ç¢¼ | èªªæ˜ | è™•ç†æ–¹å¼ |
|--------|------|----------|
| `PENDING` | ä»»å‹™ç­‰å¾…åŸ·è¡Œ | ç¹¼çºŒè¼ªè©¢ |
| `STARTED` | ä»»å‹™æ­£åœ¨åŸ·è¡Œä¸­ | ç¹¼çºŒè¼ªè©¢ |
| `SUCCESS` | ä»»å‹™å®ŒæˆæˆåŠŸ | ç²å–çµæœ |
| `FAILURE` | ä»»å‹™åŸ·è¡Œå¤±æ•— | æŸ¥çœ‹éŒ¯èª¤ä¿¡æ¯ |

---

### ğŸš€ å¿«é€Ÿæ¸¬è©¦å‘½ä»¤

#### 1. å¥åº·æª¢æŸ¥
```bash
curl -X GET "http://127.0.0.1:8000/healthz"
```

#### 2. ç²å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
```bash
curl -X GET "http://127.0.0.1:8000/maya-v2/available-models/"
```

#### 3. æ¸¬è©¦åŒæ­¥ API (LangGraph å·¥ä½œæµ)
```bash
curl -X POST "http://127.0.0.1:8000/maya-v2/ask-with-model/" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "ä½ å¥½ï¼Œé€™æ˜¯ä¸€å€‹æ¸¬è©¦å•é¡Œã€‚è«‹ç°¡å–®ä»‹ç´¹ä¸€ä¸‹ä½ è‡ªå·±ã€‚",
    "model_name": "gpt-4o-mini",
    "sync": true,
    "use_knowledge_base": true
  }'
```

#### 4. æ¸¬è©¦ç•°æ­¥ API (Celery ä»»å‹™)
```bash
curl -X POST "http://127.0.0.1:8000/maya-v2/ask-with-model/" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "é€™æ˜¯ä¸€å€‹ç•°æ­¥æ¸¬è©¦å•é¡Œã€‚è«‹å‘Šè¨´æˆ‘ä»Šå¤©çš„æ—¥æœŸã€‚",
    "model_name": "gpt-4o-mini",
    "sync": false,
    "use_knowledge_base": true
  }'
```

#### 5. æ¸¬è©¦å·¥å…·é¸æ“‡åŠŸèƒ½
```bash
curl -X POST "http://127.0.0.1:8000/maya-v2/ask-with-model/" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "è«‹å¹«æˆ‘è¨ˆç®— 123 + 456 ç­‰æ–¼å¤šå°‘ï¼Ÿ",
    "model_name": "gpt-4o-mini",
    "sync": true,
    "use_knowledge_base": true
  }'
```

#### 6. æ¸¬è©¦ç·¨ç¨‹å•é¡Œ (çŸ¥è­˜åº«æª¢ç´¢)
```bash
curl -X POST "http://127.0.0.1:8000/maya-v2/ask-with-model/" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Python ä¸­çš„è£é£¾å™¨æ˜¯ä»€éº¼ï¼Ÿ",
    "model_name": "gpt-4o-mini",
    "sync": true,
    "use_knowledge_base": true
  }'
```

#### 7. æ¸¬è©¦èŠå¤©æ­·å²
```bash
curl -X GET "http://127.0.0.1:8000/maya-sawa/qa/chat-history/test_session_123/"
```

### ğŸ“‹ é æœŸå›æ‡‰æ ¼å¼

#### **åŒæ­¥ API æˆåŠŸå›æ‡‰**
```json
{
  "session_id": "qa-1f44cbba",
  "conversation_id": "de71a9c9-c932-4735-bf0e-4bf3a8c477dc",
  "question": "ä½ å¥½ï¼Œé€™æ˜¯ä¸€å€‹æ¸¬è©¦å•é¡Œã€‚è«‹ç°¡å–®ä»‹ç´¹ä¸€ä¸‹ä½ è‡ªå·±ã€‚",
  "ai_model": {
    "id": 6,
    "name": "GPT-4o Mini",
    "provider": "openai"
  },
  "status": "completed",
  "ai_response": "ä½ å¥½ï¼æˆ‘æ˜¯ä¸€å€‹ AI åŠ©æ‰‹...",
  "knowledge_used": true,
  "knowledge_citations": [
    {
      "article_id": 16,
      "title": "ç›¸é—œæ–‡ç« æ¨™é¡Œ",
      "file_path": "article.md",
      "source": "paprika_16",
      "source_url": "https://example.com/article.md",
      "provider": "Paprika"
    }
  ],
  "message": "AIå›ç­”å·²å®Œæˆ"
}
```

#### **ç•°æ­¥ API æäº¤å›æ‡‰**
```json
{
  "task_id": "a7e35f8e-c09d-4a25-868b-dd97173c00c6",
  "status": "queued",
  "message": "Task has been queued for processing",
  "conversation_id": "461daa00-29ad-45c0-bb95-5170a6bbbe3c",
  "question": "Java ä¸­çš„å¤šç·šç¨‹æ˜¯ä»€éº¼ï¼Ÿ",
  "ai_model": {
    "id": 6,
    "name": "GPT-4o Mini",
    "provider": "openai"
  }
}
```

#### **ç•°æ­¥ API å®Œæˆå›æ‡‰**
```json
{
  "task_id": "a7e35f8e-c09d-4a25-868b-dd97173c00c6",
  "status": "SUCCESS",
  "ai_response": "Java ä¸­çš„å¤šç·šç¨‹æ˜¯æŒ‡...",
  "conversation_id": "461daa00-29ad-45c0-bb95-5170a6bbbe3c",
  "question": "Java ä¸­çš„å¤šç·šç¨‹æ˜¯ä»€éº¼ï¼Ÿ",
  "ai_model": {
    "id": 6,
    "name": "GPT-4o Mini",
    "provider": "openai"
  },
  "processing_time": 2.5,
  "completed_at": "2025-08-25T10:52:40Z",
  "knowledge_used": true,
  "knowledge_citations": [
    {
      "article_id": 16,
      "title": "Java å¤šç·šç¨‹æŒ‡å—",
      "file_path": "java-multithreading.md",
      "source": "paprika_16",
      "source_url": "https://example.com/java-multithreading.md",
      "provider": "Paprika"
    }
  ],
  "metadata": {
    "task_id": "a7e35f8e-c09d-4a25-868b-dd97173c00c6",
    "status": "completed"
  }
}
```

#### **éŒ¯èª¤å›æ‡‰æ ¼å¼**
```json
{
  "error": "éŒ¯èª¤è¨Šæ¯",
  "details": "è©³ç´°éŒ¯èª¤ä¿¡æ¯ï¼ˆå¯é¸ï¼‰"
}
```

### å®Œæ•´æ¸¬è©¦è…³æœ¬

#### é‹è¡Œ bash æ¸¬è©¦è…³æœ¬
```bash
# çµ¦è…³æœ¬åŸ·è¡Œæ¬Šé™
chmod +x test_curl_api.sh

# é‹è¡Œæ¸¬è©¦
./test_curl_api.sh
```

#### é‹è¡Œ Python æ¸¬è©¦
```bash
python test_celery_langgraph.py
```

### å…¶ä»– API ç«¯é»

#### æ·»åŠ  AI æ¨¡å‹
```bash
curl -X POST "http://127.0.0.1:8000/maya-v2/add-model/"
```

#### ä½¿ç”¨æŒ‡å®šæ¨¡å‹é€²è¡Œå°è©±
```bash
# ä½¿ç”¨ GPT-4o-mini æ¨¡å‹
curl -X POST "http://127.0.0.1:8000/maya-v2/ask-with-model/" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "ä»€éº¼æ˜¯Java",
    "model_name": "gpt-4o-mini",
    "sync": true,
    "use_knowledge_base": true
  }'

# ä½¿ç”¨ Gemini 1.5 Flash æ¨¡å‹
curl -X POST "http://127.0.0.1:8000/maya-v2/ask-with-model/" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "å¦‚ä½•å¯¦ç¾å¤šç·šç¨‹",
    "model_name": "gemini-1.5-flash",
    "sync": true,
    "use_knowledge_base": true
  }'

```

### æœå‹™å•Ÿå‹•æª¢æŸ¥

#### 1. Django æœå‹™å™¨æœªé‹è¡Œ
```bash
# å•Ÿå‹• Django æœå‹™å™¨
poetry run python manage.py runserver
```

#### 2. Celery Worker æœªé‹è¡Œ
```bash
# å•Ÿå‹• Celery Worker
poetry run celery -A config worker -l info -Q maya_v2
```

#### 3. RabbitMQ æœªé‹è¡Œ
```bash
# å•Ÿå‹• RabbitMQ
docker run -d --name rabbitmq -p 5672:5672 -p 15672:15672 \
  -e RABBITMQ_DEFAULT_USER=admin -e RABBITMQ_DEFAULT_PASS=admin123 \
  rabbitmq:3-management
```

#### 4. æª¢æŸ¥ RabbitMQ ç®¡ç†ç•Œé¢
```bash
# è¨ªå•ç®¡ç†ç•Œé¢
open http://localhost:15672
# ç”¨æˆ¶å: admin
# å¯†ç¢¼: admin123
```

#### 5. æª¢æŸ¥ Celery ç‹€æ…‹
```bash
# æª¢æŸ¥ Celery Worker ç‹€æ…‹
poetry run celery -A config inspect active

# æª¢æŸ¥éšŠåˆ—ç‹€æ…‹
poetry run celery -A config inspect stats
```

### ç›£æ§å’Œæ—¥èªŒ

#### æŸ¥çœ‹ Django æ—¥èªŒ
```bash
poetry run python manage.py runserver --verbosity=2
```

#### æŸ¥çœ‹ Celery Worker æ—¥èªŒ
```bash
poetry run celery -A config worker -l debug -Q maya_v2
```

#### æŸ¥çœ‹ RabbitMQ æ—¥èªŒ
```bash
docker logs rabbitmq
```

## éƒ¨ç½²

### Docker éƒ¨ç½²
```bash
# æ§‹å»ºæ˜ åƒ
docker build -t maya-sawa-v2 .

# é‹è¡Œå®¹å™¨
docker run -d \
  --name maya-sawa-v2 \
  -p 8000:8000 \
  --env-file .env \
  maya-sawa-v2
```

### ç”Ÿç”¢ç’°å¢ƒé…ç½®
```bash
# è¨­ç½®ç”Ÿç”¢ç’°å¢ƒè®Šæ•¸
DJANGO_SETTINGS_MODULE=config.settings.production
DJANGO_DEBUG=false
DJANGO_ADMIN_URL=your_admin_url

# è³‡æ–™åº«é€£ç·šæ± é…ç½®
DB_CONNECTION=pgsql
DB_HOST=your_db_host
DB_PORT=5432
DB_DATABASE=your_db_name
DB_USERNAME=your_db_user
DB_PASSWORD=your_db_password
DB_SSLMODE=require

# Redis é…ç½®
REDIS_URL=redis://:password@host:port/0
CELERY_BROKER_URL=redis://:password@host:port/0
CELERY_RESULT_BACKEND=redis://:password@host:port/0
```

### ç›£æ§é€£æ¥ä½¿ç”¨
```bash
# æª¢æŸ¥ç•¶å‰é€£æ¥ç‹€æ…‹
poetry run python manage.py check_db_connections

# æŒçºŒç›£æ§é€£æ¥ä½¿ç”¨
poetry run python manage.py monitor_connections --interval 10 --count 20
```

### ç®¡ç†å‘½ä»¤
```bash
# è¨­ç½® AI æ¨¡å‹
poetry run python manage.py setup_ai_models

# åˆ‡æ› API å®‰å…¨è¨­ç½®
poetry run python manage.py toggle_api_security

# å›å¡«æ–‡ç« åµŒå…¥å‘é‡
poetry run python manage.py backfill_article_embeddings

# æŸ¥çœ‹å¯ç”¨æ¨¡å‹
poetry run python manage.py shell
>>> from maya_sawa_v2.ai_processing.models import AIModel
>>> AIModel.objects.filter(is_active=True).values('name', 'provider', 'model_id')
```

## æˆæ¬Š

MIT License
